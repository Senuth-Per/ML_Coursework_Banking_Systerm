{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvS8i3CeIW6Mlp9/pq6xCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Senuth-Per/ML_Coursework_Banking_Systerm/blob/main/Ml_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset with the proper delimiter (semicolon)\n",
        "data_full_additional = pd.read_csv('/content/drive/MyDrive/ML_CW/Colab Notebooks/bank-additional-full - Copy.csv', delimiter=';')\n",
        "\n",
        "# Step 1: Remove duplicates\n",
        "print(f\"Initial dataset shape: {data_full_additional.shape}\")\n",
        "data_full_additional = data_full_additional.drop_duplicates()\n",
        "print(f\"Shape after removing duplicates: {data_full_additional.shape}\")\n",
        "\n",
        "# Step 2: Handle \"unknown\" values in categorical features\n",
        "categorical_cols = [\n",
        "    'job', 'marital', 'education', 'default', 'housing',\n",
        "    'loan', 'contact', 'month', 'day_of_week', 'poutcome'\n",
        "]\n",
        "\n",
        "# Add binary flag columns to indicate \"unknown\" values\n",
        "for col in categorical_cols:\n",
        "    if data_full_additional[col].str.contains('unknown').any():\n",
        "        data_full_additional[f'is_unknown_{col}'] = (data_full_additional[col] == 'unknown').astype(int)\n",
        "\n",
        "# Replace \"unknown\" with NaN for imputation\n",
        "data_full_additional[categorical_cols] = data_full_additional[categorical_cols].replace('unknown', np.nan)\n",
        "\n",
        "# Step 3: Handle missing values\n",
        "# Impute categorical columns with the most frequent value\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "data_full_additional[categorical_cols] = cat_imputer.fit_transform(data_full_additional[categorical_cols])\n",
        "\n",
        "# Step 4: One-hot encoding for non-ordinal categorical variables\n",
        "non_ordinal_cols = ['job', 'marital', 'contact', 'poutcome', 'month', 'day_of_week']\n",
        "data_full_additional = pd.get_dummies(data_full_additional, columns=non_ordinal_cols, drop_first=True)\n",
        "\n",
        "# Step 5: Map ordinal categorical variables\n",
        "education_mapping = {\n",
        "    'basic.4y': 1, 'basic.6y': 2, 'basic.9y': 3, 'high.school': 4,\n",
        "    'illiterate': 5, 'professional.course': 6, 'university.degree': 7\n",
        "}\n",
        "default_mapping = {'no': 0, 'yes': 1}\n",
        "housing_mapping = {'no': 0, 'yes': 1}\n",
        "loan_mapping = {'no': 0, 'yes': 1}\n",
        "\n",
        "data_full_additional['education'] = data_full_additional['education'].map(education_mapping)\n",
        "data_full_additional['default'] = data_full_additional['default'].map(default_mapping)\n",
        "data_full_additional['housing'] = data_full_additional['housing'].map(housing_mapping)\n",
        "data_full_additional['loan'] = data_full_additional['loan'].map(loan_mapping)\n",
        "\n",
        "# Step 6: Exclude the 'duration' feature for realistic predictive modeling\n",
        "data_full_additional = data_full_additional.drop(columns=['duration'])\n",
        "\n",
        "# Step 7: Scale numerical features\n",
        "numerical_cols = [\n",
        "    'age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
        "    'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
        "]\n",
        "scaler = StandardScaler()\n",
        "data_full_additional[numerical_cols] = scaler.fit_transform(data_full_additional[numerical_cols])\n",
        "\n",
        "# Step 8: Target encoding\n",
        "# Encode the target variable (y)\n",
        "data_full_additional['y'] = data_full_additional['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Step 9: Add derived features from numerical data\n",
        "data_full_additional['interaction_emp_cons'] = data_full_additional['emp.var.rate'] * data_full_additional['cons.price.idx']\n",
        "data_full_additional['interaction_nr_employed_conf'] = data_full_additional['nr.employed'] * data_full_additional['cons.conf.idx']\n",
        "\n",
        "# Step 10: Split features and target variable\n",
        "X_full_additional = data_full_additional.drop(columns=['y'])\n",
        "y_full_additional = data_full_additional['y']\n",
        "\n",
        "# Step 11: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full_additional, y_full_additional, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Save the entire preprocessed dataset\n",
        "processed_data_path = '/content/drive/MyDrive/banking_system/pre_processed_data.csv'\n",
        "data_full_additional.to_csv(processed_data_path, index=False)\n",
        "print(f\"Preprocessed dataset saved to {processed_data_path}\")\n",
        "\n",
        "# Step 12: Save processed data for model training if needed\n",
        "X_train.to_csv('/content/drive/MyDrive/banking_system/processed_X_train.csv', index=False)\n",
        "y_train.to_csv('/content/drive/MyDrive/banking_system/processed_y_train.csv', index=False)\n",
        "X_test.to_csv('/content/drive/MyDrive/banking_system/processed_X_test.csv', index=False)\n",
        "y_test.to_csv('/content/drive/MyDrive/banking_system/processed_y_test.csv', index=False)\n",
        "\n",
        "# Display dataset shapes\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdpMA9NhFkZT",
        "outputId": "d62ad2c1-a446-4353-c4db-557e8e26a1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (41188, 21)\n",
            "Shape after removing duplicates: (41176, 21)\n",
            "Preprocessed dataset saved to /content/drive/MyDrive/banking_system/pre_processed_data.csv\n",
            "Training data shape: (32940, 49)\n",
            "Testing data shape: (8236, 49)\n"
          ]
        }
      ]
    }
  ]
}